{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lendo todos os arquivos csv do diretório e guardar em um objeto\n",
    "\n",
    "```python\n",
    "\n",
    "    Primeiramente vamos ler todos arquivos xlsx que estão presentes em um diretório cujo nome. \n",
    "    Então, criamos uma função anônima (lambda) para varrer todos os arquivos xlsx e restringimos a nossa condição de busca ao \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ler todos os arquivos csv do diretório e guardar em um objeto\n",
    "# import required modules\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from dask import dataframe as dd\n",
    "\n",
    "diretorio = r'C:\\Users\\ABRASEL NACIONAL\\Documents\\CNPJ_PROGRAMATICA\\PROJETO_ESTABELECIMENTOS_CNPJ\\Bases/'\n",
    "all_files = list(filter(lambda x: '.csv' in x, os.listdir(diretorio)))\n",
    "\n",
    "#Warnings: Possui uma série de funções e comandos para tratamento de mensagens de avisos e alertas do Python\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#Comando para exibir todas colunas do arquivo\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Realizando a leitura para cada arquivo\n",
    "```python\n",
    "        Podemos fazer a leitura de todos os arquivos presentes no diretório criando uma lista vazia (full_dataset) e utilizamos um loop para fazer a leitura de cada arquivo e, assim preenchermos a lista utilizando o método append.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CNPJ = {\"EMPRE\" : ['CNPJ_BASE', 'RAZAO_SOCIAL', 'NATUREZA_JURIDICA' , 'QUALIFICACAO' ,\n",
    "          'VALOR_CAPITAL_SOCIAL' , 'PORTE_EMPRESA'  , 'ENTE_FEDERATIVO'],\n",
    "\n",
    "\"ESTABELE\" : ['CNPJ_BASE', 'CNPJ_ORDEM' , 'CNPJ_DV' , 'MATRIZ_FILIAL'  , 'NOME_FANTASIA' , 'SITUACAO_CADASTRAL' ,\n",
    "              'DATA_SITUACAO_CADASTRAL'  , 'MOTIVO_SITUACAO_CADASTRAL'  , 'CIDADE_EXTERIOR'  , 'PAIS'  , 'DATA_INICIO_ATIVIDADE'  ,\n",
    "              'CNAE_PRINCIPAL'  , 'CNAE_SECUNDARIO' , 'TIPO_LOGRADOURO'  , 'LOGRADOURO'  , 'NUMERO'  , 'COMPLEMENTO' ,\n",
    "              'BAIRRO'  , 'CEP'  , 'UF'  , 'MUNICIPIO'  , 'DDD1'  , 'TELEFONE1'  , 'DDD2'  , 'TELEFONE2'  ,\n",
    "              'DDD_FAX'  , 'FAX'  , 'EMAIL'  , 'SITUACAO_ESPECIAL'  , 'DATA_SITUACAO_ESPECIAL'],  \n",
    "\n",
    "\"SIMPLES\" : ['CNPJ_BASE'  , 'OPCAO_SIMPLES'  , 'DATA_OPCAO_SIMPLES'  , 'DATA_EXCLUSAO_SIMPLES'  ,\n",
    "             'OPCAO_MEI'  , 'DATA_OPCAO_MEI'  , 'DATA_EXCLUSAO_MEI'],\n",
    "\n",
    "\"SOCIO\" : ['CNPJ_BASE'  , 'TIPO'  , 'NOME'  , 'CPF_CNPJ'  , 'QUALIFICACAO'  , 'DATA_ENTRADA' ,\n",
    "            'PAIS' , 'REPRESENTANTE'  , 'NOME_REPRESENTANTE'  , 'QUALIFICACAO_REPRESENTANTE'  , 'FAIXA_ETARIA'  ],\n",
    "\n",
    "\"PAIS\" : ['CODIGO_PAIS' , 'PAIS'],\n",
    "\n",
    "\"MUNIC\" : ['MUNICIPIO'  , 'MUNICIPIO'  ],\n",
    "\n",
    "\"QUALS\" : ['QUALIFICACAO', 'QUALIFICACAO' ],\n",
    "\n",
    "\"NATJU\" : ['NATUREZA_JURIDICA'  , 'NATUREZA_JURIDICA'],\n",
    "\n",
    "\"MOTI\" : ['MOTIVO_SITUACAO_CADASTRAL'  , 'MOTIVO_SITUACAO_CADASTRAL'  ],\n",
    "\n",
    "\"CNAE\" : ['CODIGO_CNAE'  , 'CNAE' ]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNAES = {5611201:'Restaurantes e similares',\n",
    "        5611203:'Lanchonetes casas de chá de sucos e similares',\n",
    "        5611204:'Bares e outros estabelecimentos especializados em servir bebidas sem entretenimento',\n",
    "        5611205:'Bares e outros estabelecimentos especializados em servir bebidas com entretenimento',\n",
    "        5612100: 'Serviços ambulantes de alimentação'}\n",
    "\n",
    "lista_cnae = []\n",
    "for cnae in CNAES.keys():\n",
    "    lista_cnae.append(cnae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cnae in lista_cnae:\n",
    "    print(CNAES[cnae])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nome: Bares e outros estabelecimentos especializados em servir bebidas com entretenimento.csv Tamanho: (11595, 30)\n",
      "Nome: Bares e outros estabelecimentos especializados em servir bebidas sem entretenimento.csv Tamanho: (29971, 30)\n",
      "Nome: Lanchonetes casas de chá de sucos e similares.csv Tamanho: (128165, 30)\n",
      "Nome: Restaurantes e similares.csv Tamanho: (85171, 30)\n",
      "Nome: Serviços ambulantes de alimentação.csv Tamanho: (36918, 30)\n"
     ]
    }
   ],
   "source": [
    "for file in all_files:\n",
    "    ffile =re.sub(\" \",\"_\",file)\n",
    "    globals()[f'{ffile}'] = pd.read_csv(f'{diretorio}/{file}',sep=';',encoding='utf-8', names=CNPJ['ESTABELE'],low_memory=False)\n",
    "    print(f'Nome: {file} Tamanho: {globals()[f\"{ffile}\"].shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "        5611201, -- Restaurantes e similares\n",
    "        5611203, -- Lanchonetes casas de chá de sucos e similares\n",
    "        5611204, -- Bares e outros estabelecimentos especializados em servir bebidas sem entretenimento\n",
    "        5611205 -- Bares e outros estabelecimentos especializados em servir bebidas com entretenimento\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = dados.loc[dados['CNAE_PRINCIPAL']== 5611201]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataframes = []\n",
    "for cnae in lista_cnae:\n",
    "    globals()[f'df_{cnae}'] = dados.loc[dados['CNAE_PRINCIPAL']== cnae]\n",
    "    dataframes.append(f'df_{cnae}')\n",
    "dados = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# realizar a leitura para cada arquivo\n",
    "\n",
    "full_dataset = []\n",
    "for arq in all_files:\n",
    "    frags = arq.split('.')\n",
    "    frame = frags[1]\n",
    "    globals()[f\"df_{frame}\"] = pd.read_csv(f'{diretorio}{arq}',sep=';' ,encoding=\"ISO-8859-1\", nrows=50, names=CNPJ['ESTABELE'])\n",
    "    #data = pd.read_csv(f'{diretorio}{arq}',sep=';' ,encoding=\"ISO-8859-1\", nrows=50, names=CNPJ['ESTABELE'])\n",
    "    full_dataset.append(globals()[f\"df_{frame}\"])\n",
    "    #full_dataset.append(data)    \n",
    "    globals()[f\"df_{frame}\"].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(full_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estabelecendo a conexão e criando o banco\n",
    "\n",
    "```python\n",
    "    Vamos criar uma conexão com o SQLite. \n",
    "    O único parâmetro que vamos passar é o nome do banco que será criado.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "# estabelecendo a conexão e criando o banco\n",
    "con = sqlite3.connect('database_estabelecimento_sodexo.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtendo os nomes das tabelas\n",
    "        \n",
    "```python\n",
    "        Para obter o nome das nossas tabelas utilizamos como referência o nome dos arquivos xlsx. \n",
    "        O método splitext é o responsável por separar entre o nome do arquivo e a extensão. \n",
    "        O valor cujo índice é [0] garante que pegaremos apenas a primeira coluna com os nomes dos arquivos.\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtendo os nomes das tabelas\n",
    "table_names = [os.path.splitext(arq)[0] for arq in all_files]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtendo os campos de todas as tabelas\n",
    "    \n",
    "```python\n",
    "        Em seguida, obteremos os campos de todas as tabelas. Dentro do laço, coletamos a primeira linha (cabeçalho) e armazenamos em columnNames finalizando com um append na lista table_fields.\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtendo os campos de todas as tabelas\n",
    "table_fields = []\n",
    "for i in range(0,len(table_names)):\n",
    "    columnNames = list(full_dataset[i].head(0))\n",
    "    table_fields.append(columnNames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulando o BD\n",
    "```python\n",
    "    Antes da criação e inserção de dados, é necessário definirmos um cursor para interagir com os registros do BD.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "cur = con.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando as tabelas no SQLite\n",
    "    \n",
    "```python\n",
    "        Nesse momento, criaremos as tabelas dentro do SQlite. \n",
    "        Para cada elemento das minhas tabelas do xsxl, executamos uma query para criação das tabelas. \n",
    "        Passando para a função execute() o nome da tabela (table_names[item]) bem como os campos que as compõe utilizando o separador vírgula \n",
    "    \n",
    "(‘,’.join(table_fields[item])).\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE IF NOT EXISTS November_Estabelecimentos_Sodexo_Atualizado ( Estabelecimento,Endereço,Cidade_UF,Telefone,Latitude,Longitude )\n"
     ]
    }
   ],
   "source": [
    "# criando as tabelas no SQLite\n",
    "for item in range(0,len(table_names)):\n",
    "    cur.execute(f\"\"\"CREATE TABLE IF NOT EXISTS {table_names[item] } ( {','.join(table_fields[item])} )\"\"\")\n",
    "    print(f\"\"\"CREATE TABLE IF NOT EXISTS {table_names[item] } ( {','.join(table_fields[item])} )\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Varrendo todas as tabelas e para cada uma é realizado a inserção dos dados\n",
    "```python\n",
    "\n",
    "        A última etapa é realizar a carga dos registros em todas as tabelas. \n",
    "        Isso será feito por um laço de repetição que percorre cada tabela realizando a carga dos registros e em seguida grava a execução utilizando o commit().\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Varre todas as tabelas e para cada uma é realizada a inserção dos dados\n",
    "for i in range(0, len(table_names)):\n",
    "\n",
    "    query = f\"\"\"INSERT INTO  {str(table_names[i])} ( {','.join(table_fields[i])}  ) VALUES ( {','.join(map(str,'?'*len(full_dataset[i].columns)))} )\"\"\"\n",
    "\n",
    "\n",
    "    full_dataset[i] = full_dataset[i].astype(str)\n",
    "\n",
    "    for j in range(0, len(full_dataset[i])):\n",
    "        insert_register = tuple(full_dataset[i].iloc[j])\n",
    "        cur.execute(query, insert_register)\n",
    "        con.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função Select nos dados\n",
    "    \n",
    "```python\n",
    "        Chamando a função com parâmetros CAMPO, TABELA, WHERE, CONDIÇÃO \n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SELECT_WHERE(campo:str = '*' ,tabela:str = table_names[0], where:str = table_fields[0][2], condicao:str = 'Belo Horizonte, MG'):\n",
    "    select = f\"\"\" SELECT {campo} FROM {tabela}\n",
    "            WHERE {where} = '{condicao}'\n",
    "    \"\"\"\n",
    "\n",
    "    cur.execute(select)\n",
    "    rows = cur.fetchall()\n",
    "    print(len(rows))\n",
    "    for row in rows:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT_WHERE()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "33b937bef43efa2a1535649a0ecede60f732469583961989e654da1c5a454a04"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
