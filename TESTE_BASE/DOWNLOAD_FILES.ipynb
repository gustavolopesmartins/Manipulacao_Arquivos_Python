{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Libs necessárias\n",
    "def request(url:str = None,nome_arquivo:str = '', extensao:str='zip'):\n",
    "    \"\"\"AI is creating summary for request\n",
    "\n",
    "    Args:\n",
    "        url (str): Caminho online de onde possam ter redirecionamentos href.\n",
    "        nome_arquivo (str): nome do arquivo que vamos buscar ou dos arquivos se tiverem mais de um com o mesmo nome.\n",
    "        extensao (str): extenção do arquivo que vamos buscar se formos buscar por um download em específico.\n",
    "\n",
    "    Returns:\n",
    "        urls : Retorna uma lista com todos as urls que deram math com os parâmetros passados no crawler da url infomrada.\n",
    "    \"\"\"\n",
    "    import re\n",
    "    import urllib.request\n",
    "    nome_arquivo = nome_arquivo.capitalize()\n",
    "    print(nome_arquivo)\n",
    "    abre_url = urllib.request.urlopen(url)\n",
    "    \n",
    "    le_url = abre_url.read()\n",
    "\n",
    "    converte_leitura_url = le_url.decode(\"utf8\")\n",
    "    abre_url.close()\n",
    "    \n",
    "    urls = []\n",
    "    #urls = [ f\"{url}{i.replace('<', '')}\" for i in re.findall(f\"[\\w\\d]+.(?:zip|pdf|csv)<\", converte_leitura_url) if i.startswith(nome_arquivo)]\n",
    "    #urls = [f'{url}{i}.zip' for i in re.findall(f'href=\"(.*?).{extensao}', converte_leitura_url) if i.startswith(nome_arquivo)]\n",
    "    urls = [ f\"{url}{i}.{extensao}\" for i in re.findall(f'href=\"(.*).(?:{extensao})\"', converte_leitura_url) if i.startswith(nome_arquivo)]\n",
    "    \n",
    "    return urls\n",
    "def download(url:str=None, salvar_onde:str= './' ):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        url (str): URL de do arquivo para download.\n",
    "        salvar_onde (str): Pasta de destino do arquivo baixado.\n",
    "    \"\"\"\n",
    "    from pySmartDL import SmartDL\n",
    "    obj = SmartDL(url, salvar_onde)\n",
    "    obj.start()\n",
    "    path = obj.get_dest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "links = [\"https://dadosabertos.rfb.gov.br/CNPJ/\", \"http://200.152.38.155/CNPJ/\"]\n",
    "src = request(links[1])\n",
    "print(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "class EXTRATOR_CNPJ: \n",
    "    import os\n",
    "    def __init__(self, url:str = None,nome_arquivo:str = '', extensao:str='zip'): \n",
    "        self.url = url \n",
    "        self.nome_arquivo = nome_arquivo\n",
    "        self.extensao = extensao \n",
    "        \n",
    "    def request(self):\n",
    "        import re\n",
    "        import urllib.request\n",
    "        abre_url = urllib.request.urlopen(self.url)\n",
    "        le_url = abre_url.read()\n",
    "        converte_leitura_url = le_url.decode(\"utf8\")\n",
    "        abre_url.close()\n",
    "        urls = []\n",
    "        urls =  [ f\"{self.url}{i}.{self.extensao}\" for i in re.findall(f'href=\"(.*).(?:{self.extensao})\"', converte_leitura_url) if i.startswith(self.nome_arquivo)]\n",
    "        return urls\n",
    "\n",
    "    def download(self, url:str=None, destino:str = None):\n",
    "        ### Com requests\n",
    "        \"\"\"\n",
    "        import requests\n",
    "        with requests.get(url, stream=True) as response:\n",
    "            with open(os.path.join(salvar_onde, arquivo), 'wb') as f:\n",
    "                for chunk in response.iter_content(chunk_size=8192):\n",
    "                    f.write(chunk)\n",
    "\n",
    "        \"\"\"\n",
    "        ### Com urllib\n",
    "        \"\"\"\n",
    "        import urllib.request\n",
    "        arquivo = url.split('/')[-1]\n",
    "        # faz o download do arquivo e salva em salvar_onde/arquivo\n",
    "        urllib.request.urlretrieve(url, os.path.join(salvar_onde, arquivo))\n",
    "        ### Com SmartDL\n",
    "        \"\"\"\n",
    "\n",
    "        ### Com SmartDL\n",
    "        from pySmartDL import SmartDL\n",
    "\n",
    "        obj = SmartDL(url, destino, threads=4, progress_bar=False)\n",
    "        obj.start()\n",
    "        return destino\n",
    "\n",
    "    def run(self):\n",
    "        import re\n",
    "        import zipfile\n",
    "        from pyspark.sql import SparkSession\n",
    "        urls  = self.request()\n",
    "        \n",
    "        # Define ou busca uma sessão do Spark\n",
    "        spark = SparkSession.builder.master(\"local[2]\").appName(\"OnlineReader\").getOrCreate()\n",
    "        for url in urls:\n",
    "            \n",
    "            # Diretório de execução do script\n",
    "            current_dir = os.getcwd()\n",
    "            \n",
    "            # Pega o nome do arquivo pela url\n",
    "            arquivo = url.split('/')[-1]\n",
    "            \n",
    "            # Define o caminho absoluto do diretório.\n",
    "            salvar_onde = f\"{current_dir}/RAW/{arquivo.split('.')[0]}/\"\n",
    "\n",
    "            # cria a pasta para armazenar o arquivo, se ela não existir\n",
    "            if not os.path.exists(salvar_onde):\n",
    "                os.makedirs(salvar_onde)\n",
    "                \n",
    "            # download do arquivo zip\n",
    "            path = self.download(url, os.path.join(salvar_onde, arquivo))\n",
    "            \n",
    "            # descompactação do arquivo zip\n",
    "            with zipfile.ZipFile(path, 'r') as zip_ref:\n",
    "\n",
    "                # obtem o nome do primeiro arquivo dentro do zip\n",
    "                nome_original_arquivo_zip = zip_ref.namelist()[0]\n",
    "\n",
    "                # define um novo nome para o arquivo\n",
    "                novo_nome_arquivo = f\"CNPJ_{arquivo.split('.')[0]}.csv\"\n",
    "                # cria um dicionário com as informações de origem e destino\n",
    "                arquivos_para_extrair = {nome_original_arquivo_zip : novo_nome_arquivo}\n",
    "\n",
    "                # realiza a extração do arquivo zip\n",
    "                zip_ref.extractall(path = f\"{salvar_onde}\", members=arquivos_para_extrair)\n",
    "                \n",
    "                # renomeia o arquivo extraído com o novo nome\n",
    "                try:\n",
    "                    os.rename(os.path.join(salvar_onde, nome_original_arquivo_zip), os.path.join(salvar_onde, novo_nome_arquivo))\n",
    "                except Exception as e:\n",
    "                    print(f\"deu um pequeno erro aqui {e}\") \n",
    "                    os.remove(os.path.join(salvar_onde, nome_original_arquivo_zip))\n",
    "                    pass\n",
    "            # leitura do arquivo CSV em um dataframe Spark\n",
    "            csv_file = os.path.join(salvar_onde, novo_nome_arquivo)\n",
    "            dados = spark.read.options(delimiter=\";\", header=False, inferSchema=True).csv(csv_file)\n",
    "            dados.show(1, vertical=True)\n",
    "            os.remove(path)\n",
    "            return dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deu um pequeno erro aqui {e}\n",
      "-RECORD 0-------\n",
      " _c0 | 0        \n",
      " _c1 | N        \n",
      " _c2 | 20070701 \n",
      " _c3 | 20070701 \n",
      " _c4 | N        \n",
      " _c5 | 20090701 \n",
      " _c6 | 20090701 \n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: int, _c1: string, _c2: int, _c3: int, _c4: string, _c5: int, _c6: int]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://dadosabertos.rfb.gov.br/CNPJ/'\n",
    "EC_SIMPLES = EXTRATOR_CNPJ(url=url, nome_arquivo='Simples', extensao='zip')\n",
    "SIMPLES = EC_SIMPLES.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salva no disco e lê após isso\n",
    "``` PYTHON\n",
    "# Libs\n",
    "import requests # SE FOR USAR REQUESTS\n",
    "import urllib.request # SE FOR USAR URLLIB\n",
    "from pySmartDL import SmartDL # SE FOR USAR PYSMARTDL\n",
    "import zipfile\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Define ou busca uma sessão do Spark\n",
    "spark = SparkSession.builder.master(\"local[2]\") \\\n",
    "    .appName(\"OnlineReader\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Define a url de download dos dados\n",
    "url = 'https://dadosabertos.rfb.gov.br/CNPJ/Simples.zip'\n",
    "# Pega o nome do arquivo pela url\n",
    "arquivo = url.split('/')[-1]\n",
    "# Define o caminho absoluto do diretório.\n",
    "salvar_onde = f\"{current_dir}/RAW/{arquivo.split('.')[0]}/\"\n",
    "\n",
    "# cria a pasta para armazenar o arquivo, se ela não existir\n",
    "if not os.path.exists(salvar_onde):\n",
    "    os.makedirs(salvar_onde)\n",
    "\n",
    "### Com requests\n",
    "\"\"\"\n",
    "    with requests.get(url, stream=True) as response:\n",
    "        with open(os.path.join(salvar_onde, arquivo), 'wb') as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "\n",
    "\"\"\"\n",
    "### Com urllib\n",
    "\n",
    "# faz o download do arquivo e salva em salvar_onde/arquivo\n",
    "urllib.request.urlretrieve(url, os.path.join(salvar_onde, arquivo))\n",
    "\n",
    "### Com SmartDL\n",
    "\"\"\"\n",
    "    dest = os.path.join(salvar_onde, arquivo)\n",
    "    obj = SmartDL(url, dest, threads=4)\n",
    "    obj.start()\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "# Imprime o caminho do diretório de download\n",
    "print(salvar_onde)\n",
    "\"\"\"\n",
    "\n",
    "# Descompactação do arquivo\n",
    "with zipfile.ZipFile(os.path.join(salvar_onde, arquivo), 'r') as zip_ref:\n",
    "\n",
    "    # obtem o nome do primeiro arquivo dentro do zip\n",
    "    nome_original_arquivo_zip = zip_ref.namelist()[0]\n",
    "\n",
    "    # define um novo nome para o arquivo\n",
    "    novo_nome_arquivo = f\"CNPJ_{arquivo.split('.')[0]}.csv\"\n",
    "\n",
    "    # cria um dicionário com as informações de origem e destino\n",
    "    arquivos_para_extrair = {nome_original_arquivo_zip : novo_nome_arquivo}\n",
    "\n",
    "    # realiza a extração do arquivo zip\n",
    "    zip_ref.extractall(path = f\"{salvar_onde}/\", members=arquivos_para_extrair)\n",
    "    \n",
    "    # renomeia o arquivo extraído com o novo nome\n",
    "    os.rename(os.path.join(salvar_onde, nome_original_arquivo_zip), os.path.join(salvar_onde, novo_nome_arquivo))\n",
    "\n",
    "\"\"\"\n",
    "# imprime o nome do arquivo dentro do zip e o novo nome\n",
    "print(f\"Arquivo dentro do zip: {nome_original_arquivo_zip}\")\n",
    "print(f\"Novo nome do arquivo: {novo_nome_arquivo}\")\n",
    "\"\"\"\n",
    "\n",
    "# Define o caminho absoluto para o arquivo\n",
    "csv_file = os.path.join(salvar_onde, novo_nome_arquivo)\n",
    "\n",
    "# Lê o arquivo em um dataframe Spark\n",
    "dados = spark.read.options(delimiter=\";\", header=False, inferSchema=True).csv(csv_file)\n",
    "\n",
    "# Plota primeira linha do dataframe\n",
    "dados.show(1, vertical=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libs\n",
    "import requests # SE FOR USAR REQUESTS\n",
    "import urllib.request # SE FOR USAR URLLIB\n",
    "from pySmartDL import SmartDL # SE FOR USAR PYSMARTDL\n",
    "import zipfile\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Define ou busca uma sessão do Spark\n",
    "spark = SparkSession.builder.master(\"local[2]\") \\\n",
    "    .appName(\"OnlineReader\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Define a url de download dos dados\n",
    "url = 'https://dadosabertos.rfb.gov.br/CNPJ/Simples.zip'\n",
    "# Pega o nome do arquivo pela url\n",
    "arquivo = url.split('/')[-1]\n",
    "# Define o caminho absoluto do diretório.\n",
    "salvar_onde = f\"{current_dir}/RAW/{arquivo.split('.')[0]}/\"\n",
    "\n",
    "# cria a pasta para armazenar o arquivo, se ela não existir\n",
    "if not os.path.exists(salvar_onde):\n",
    "    os.makedirs(salvar_onde)\n",
    "\n",
    "### Com requests\n",
    "\"\"\"\n",
    "    with requests.get(url, stream=True) as response:\n",
    "        with open(os.path.join(salvar_onde, arquivo), 'wb') as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "\n",
    "\"\"\"\n",
    "### Com urllib\n",
    "\n",
    "# faz o download do arquivo e salva em salvar_onde/arquivo\n",
    "urllib.request.urlretrieve(url, os.path.join(salvar_onde, arquivo))\n",
    "\n",
    "### Com SmartDL\n",
    "\"\"\"\n",
    "    dest = os.path.join(salvar_onde, arquivo)\n",
    "    obj = SmartDL(url, dest, threads=4)\n",
    "    obj.start()\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "# Imprime o caminho do diretório de download\n",
    "print(salvar_onde)\n",
    "\"\"\"\n",
    "\n",
    "# Descompactação do arquivo\n",
    "with zipfile.ZipFile(os.path.join(salvar_onde, arquivo), 'r') as zip_ref:\n",
    "\n",
    "    # obtem o nome do primeiro arquivo dentro do zip\n",
    "    nome_original_arquivo_zip = zip_ref.namelist()[0]\n",
    "\n",
    "    # define um novo nome para o arquivo\n",
    "    novo_nome_arquivo = f\"CNPJ_{arquivo.split('.')[0]}.csv\"\n",
    "\n",
    "    # cria um dicionário com as informações de origem e destino\n",
    "    arquivos_para_extrair = {nome_original_arquivo_zip : novo_nome_arquivo}\n",
    "\n",
    "    # realiza a extração do arquivo zip\n",
    "    zip_ref.extractall(path = f\"{salvar_onde}/\", members=arquivos_para_extrair)\n",
    "    \n",
    "    # renomeia o arquivo extraído com o novo nome\n",
    "    os.rename(os.path.join(salvar_onde, nome_original_arquivo_zip), os.path.join(salvar_onde, novo_nome_arquivo))\n",
    "\n",
    "\"\"\"\n",
    "# imprime o nome do arquivo dentro do zip e o novo nome\n",
    "print(f\"Arquivo dentro do zip: {nome_original_arquivo_zip}\")\n",
    "print(f\"Novo nome do arquivo: {novo_nome_arquivo}\")\n",
    "\"\"\"\n",
    "\n",
    "# Define o caminho absoluto para o arquivo\n",
    "csv_file = os.path.join(salvar_onde, novo_nome_arquivo)\n",
    "\n",
    "# Lê o arquivo em um dataframe Spark\n",
    "dados = spark.read.options(delimiter=\";\", header=False, inferSchema=True).csv(csv_file)\n",
    "\n",
    "# Plota primeira linha do dataframe\n",
    "dados.show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dados' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dados\u001b[39m.\u001b[39mcount()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dados' is not defined"
     ]
    }
   ],
   "source": [
    "dados.count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
